{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f261bb5-aaaa-47c2-8353-d46ec907d932",
   "metadata": {},
   "source": [
    "### Import and check version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096a6973-733b-486d-9e85-5978a0de4cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07dccb3-5dd2-42c5-b9ba-fa8b5d2de4c3",
   "metadata": {},
   "source": [
    "### Check available devices (cpus/gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1882aa9-8435-46d9-9746-a70175360d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc33c8d-bca3-4ec0-9fe5-4ce4c809db22",
   "metadata": {},
   "source": [
    "### Show placement of tensors on devices (tensor on which device?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b4f202-7120-4316-9e66-6acc2260615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8fb06-d895-45d3-8bf7-e23c7166204a",
   "metadata": {},
   "source": [
    "### Use only cpu for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e1e093-f66e-4dd4-bbee-5f7632c6780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec5b0d-2dee-47df-9030-b1f2db1fe2fe",
   "metadata": {},
   "source": [
    "### Then use gpu for computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8352db4-f911-4285-aefb-3f004fc6dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Run on the GPU\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61f224-be7f-4e64-9466-20f7cc632fb5",
   "metadata": {},
   "source": [
    "### or use cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e1964b-6649-4471-af32-a85bc75f83be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "  d = tf.matmul(a,b)\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b90d0-e911-4478-86ff-e7905189fc5f",
   "metadata": {},
   "source": [
    "### Specify gpu to be used / Limit to certain gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6dc216-2f05-4c27-8f05-d15071157181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2071450-cdd2-4150-8674-cb4f2b9c0908",
   "metadata": {},
   "source": [
    "### Limit memory usage (grows as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9566702-ba51-496a-a71f-505218b49435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292c903-de2d-4026-98c4-e51f0a249dd9",
   "metadata": {},
   "source": [
    "### Custom gpu memory usage limit (hard limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88a6777-0e6f-4bd3-ab16-906b48d24c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1d552-a542-47c2-8bf1-b9aea5d78ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
